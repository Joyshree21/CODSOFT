{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517a6db7",
   "metadata": {},
   "source": [
    "# TASK-5 HANDWRITTEN TEXT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2809b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01db7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\JOYSHREE\\CODSOFT\\Handwritten text generation\\shakespeare.txt\"\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053dc68",
   "metadata": {},
   "source": [
    "# Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c278fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47e656ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "717c7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a1ea068",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a081c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa42c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOYSHREE\\AppData\\Local\\Temp\\ipykernel_9896\\2881699531.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  len(characters)), dtype=np.bool)\n",
      "C:\\Users\\JOYSHREE\\AppData\\Local\\Temp\\ipykernel_9896\\2881699531.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  len(characters)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c4d4e",
   "metadata": {},
   "source": [
    "# Building recurrent Neutral Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7322af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9675ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4fe917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 68s 96ms/step - loss: 2.7018\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 63s 97ms/step - loss: 2.3006\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 51s 79ms/step - loss: 2.1819\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 51s 79ms/step - loss: 2.0993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29db0eeef10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdc2b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07d5f8",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d9917c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0380d3",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a7a952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.\n",
      "\n",
      "blunt:\n",
      "he hath no friends but who ard and hear and in the with the hard i the fore the comentere the beat the these sound and here to the sand the with the mane the hare the condent the hard not hear the the candend and the hard and the come the sond the hard the wither with the hard and and the sours,\n",
      "and be the come the come the the\n",
      "dy in another room\n",
      "and triumph, henry, i bemen the and as in the byor will and the sontertand word aingery,\n",
      "and shard and the cape to eround for that and the stare to in thas and and whand ware the ingeres.\n",
      "\n",
      "chance:\n",
      "the somes ard me the come to thou hard and and wither whet soue stall not wore\n",
      "the my lond beath mise the hound sate.\n",
      "\n",
      "hachi\n",
      "\n",
      "so fill'd and so becoming: in pure whith than hond he my the sore me the sere.\n",
      "\n",
      "wing of lery:\n",
      "i win the mere and in sours of wholl forentered.\n",
      "\n",
      "bone:\n",
      "sord of my merss come the wore thich thoug the and that seale.\n",
      "\n",
      "hareing:\n",
      "and in the ford here shat me coon there the rave of the haricheagn,\n",
      "and, the breath dome the cooke the with and hing\n",
      "him up,\n",
      "are pluck'd up root and all by beick,\n",
      "you padile thit pape to beest ande,\n",
      "and and hean, and hes lime thaue fole, wind and and mines now thingaris;\n",
      "thy her with the such me mong chendent in with some came:\n",
      "that wain the bupe me you dyould the of thint\n",
      "whiy wallew te dishend come he gford\n",
      "the dored,\n",
      "and wart minet be the dond he sin\n",
      "es: there is my bond of faith,\n",
      "to tie thing cealt te all beptire's fall the hiln yourd.\n",
      "\n",
      "urino: and betwer\n",
      "not with werlo hour tofres sling heres,\n",
      "a wive the gowne not freach at in to to the suech\n",
      "at, thoug is in watt a mare the groterene!\n",
      "\n",
      "hachim:\n",
      "and! ford\n",
      "the myoud stain sould wat, wlow huth fors, and i wicl,\n",
      "me come fotl, share you go\n",
      "hen you shall come to clearer knowledge, that and wing in thee fablongee,\n",
      "nod'd thine follos nowifomy bee beast.\n",
      "\n",
      "y vaeler:\n",
      "atw this theis'ling,\n",
      "be serwind in, him, and as ut lave to thar oming\n",
      "ad,\n",
      "and werd thee a than wall se why ford obrt,\n",
      "woll b'in comeind deapne sicht my i sear.\n",
      "\n",
      "tousth:\n",
      "and ard ie and kentere sver wery end sole chart\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d8df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
